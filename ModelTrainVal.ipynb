{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a21a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "from HousePriceDataset import HousePriceDataset\n",
    "from PredictorModel import HousePricePredictor\n",
    "from ModelTrainingEpoch import model_training_epoch\n",
    "from ModelValidationEpoch import model_validation_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932b030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Preprocess Data\n",
    "housing_price_dataset = pd.read_csv(\"housing.csv\")\n",
    "housing_price_dataset.columns = housing_price_dataset.columns.str.strip()\n",
    "\n",
    "housing_data_input = housing_price_dataset.drop(columns=[\"median_house_value\", \"ocean_proximity\"])\n",
    "housing_data_output = housing_price_dataset[\"median_house_value\"]\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    housing_price_dataset,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "X_train_raw = train_df.drop(columns=[\"median_house_value\", \"ocean_proximity\"], errors='ignore')\n",
    "Y_train_raw = train_df[\"median_house_value\"]\n",
    "\n",
    "X_test_raw = test_df.drop(columns=[\"median_house_value\", \"ocean_proximity\"], errors='ignore')\n",
    "Y_test_raw = test_df[\"median_house_value\"]\n",
    "\n",
    "# Scaling\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_x.fit_transform(X_train_raw.values)\n",
    "Y_train = scaler_y.fit_transform(Y_train_raw.values.reshape(-1, 1))\n",
    "\n",
    "X_test = scaler_x.transform(X_test_raw.values)\n",
    "Y_test = scaler_y.transform(Y_test_raw.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427e497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup DataLoaders\n",
    "train_dataset = HousePriceDataset(X_train, Y_train)\n",
    "val_dataset = HousePriceDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1d52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HousePricePredictor(input_dim=X_train.shape[1])\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c78a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training on cpu...\n",
      "Epoch [1/50] Train Loss: 0.3508 Val Loss: nan\n",
      "Epoch [2/50] Train Loss: 0.2920 Val Loss: nan\n",
      "Epoch [3/50] Train Loss: 0.2788 Val Loss: nan\n",
      "Epoch [4/50] Train Loss: 0.2712 Val Loss: nan\n",
      "Epoch [5/50] Train Loss: 0.2649 Val Loss: nan\n",
      "Epoch [6/50] Train Loss: 0.2593 Val Loss: nan\n",
      "Epoch [7/50] Train Loss: 0.2547 Val Loss: nan\n",
      "Epoch [8/50] Train Loss: 0.2466 Val Loss: nan\n",
      "Epoch [9/50] Train Loss: 0.2406 Val Loss: nan\n",
      "Epoch [10/50] Train Loss: 0.2370 Val Loss: nan\n",
      "Epoch [11/50] Train Loss: 0.2334 Val Loss: nan\n",
      "Epoch [12/50] Train Loss: 0.2283 Val Loss: nan\n",
      "Epoch [13/50] Train Loss: 0.2256 Val Loss: nan\n",
      "Epoch [14/50] Train Loss: 0.2240 Val Loss: nan\n",
      "Epoch [15/50] Train Loss: 0.2215 Val Loss: nan\n",
      "Epoch [16/50] Train Loss: 0.2194 Val Loss: nan\n",
      "Epoch [17/50] Train Loss: 0.2194 Val Loss: nan\n",
      "Epoch [18/50] Train Loss: 0.2168 Val Loss: nan\n",
      "Epoch [19/50] Train Loss: 0.2151 Val Loss: nan\n",
      "Epoch [20/50] Train Loss: 0.2133 Val Loss: nan\n",
      "Epoch [21/50] Train Loss: 0.2125 Val Loss: nan\n",
      "Epoch [22/50] Train Loss: 0.2111 Val Loss: nan\n",
      "Epoch [23/50] Train Loss: 0.2099 Val Loss: nan\n",
      "Epoch [24/50] Train Loss: 0.2089 Val Loss: nan\n",
      "Epoch [25/50] Train Loss: 0.2075 Val Loss: nan\n",
      "Epoch [26/50] Train Loss: 0.2071 Val Loss: nan\n",
      "Epoch [27/50] Train Loss: 0.2058 Val Loss: nan\n",
      "Epoch [28/50] Train Loss: 0.2040 Val Loss: nan\n",
      "Epoch [29/50] Train Loss: 0.2045 Val Loss: nan\n",
      "Epoch [30/50] Train Loss: 0.2024 Val Loss: nan\n",
      "Epoch [31/50] Train Loss: 0.2020 Val Loss: nan\n",
      "Epoch [32/50] Train Loss: 0.2016 Val Loss: nan\n",
      "Epoch [33/50] Train Loss: 0.2011 Val Loss: nan\n",
      "Epoch [34/50] Train Loss: 0.2008 Val Loss: nan\n",
      "Epoch [35/50] Train Loss: 0.2005 Val Loss: nan\n",
      "Epoch [36/50] Train Loss: 0.1999 Val Loss: nan\n",
      "Epoch [37/50] Train Loss: 0.1989 Val Loss: nan\n",
      "Epoch [38/50] Train Loss: 0.1985 Val Loss: nan\n",
      "Epoch [39/50] Train Loss: 0.2001 Val Loss: nan\n",
      "Epoch [40/50] Train Loss: 0.1972 Val Loss: nan\n",
      "Epoch [41/50] Train Loss: 0.1964 Val Loss: nan\n",
      "Epoch [42/50] Train Loss: 0.1970 Val Loss: nan\n",
      "Epoch [43/50] Train Loss: 0.1963 Val Loss: nan\n",
      "Epoch [44/50] Train Loss: 0.1945 Val Loss: nan\n",
      "Epoch [45/50] Train Loss: 0.1947 Val Loss: nan\n",
      "Epoch [46/50] Train Loss: 0.1944 Val Loss: nan\n",
      "Epoch [47/50] Train Loss: 0.1944 Val Loss: nan\n",
      "Epoch [48/50] Train Loss: 0.1933 Val Loss: nan\n",
      "Epoch [49/50] Train Loss: 0.1933 Val Loss: nan\n",
      "Epoch [50/50] Train Loss: 0.1924 Val Loss: nan\n"
     ]
    }
   ],
   "source": [
    "# 4. Training Loop\n",
    "num_epochs = 50\n",
    "print(f\"Starting model training on {device}...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = model_training_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    val_loss = model_validation_epoch(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} \"\n",
    "        f\"Val Loss: {val_loss:.4f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
