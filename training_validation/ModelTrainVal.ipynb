{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a21a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required Libraries\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from data.HousePriceDataset import HousePriceDataset\n",
    "from model.PredictorModel import HousePricePredictor\n",
    "from ModelTrainingEpoch import model_training_epoch\n",
    "from ModelValidationEpoch import model_validation_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "932b030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Preprocess Data\n",
    "housing_price_dataset = pd.read_csv(\"../data/housing.csv\")\n",
    "housing_price_dataset.columns = housing_price_dataset.columns.str.strip()\n",
    "\n",
    "housing_data_input = housing_price_dataset.drop(columns=[\"median_house_value\", \"ocean_proximity\"])\n",
    "housing_data_output = housing_price_dataset[\"median_house_value\"]\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    housing_price_dataset,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "X_train_raw = train_df.drop(columns=[\"median_house_value\", \"ocean_proximity\"], errors='ignore')\n",
    "Y_train_raw = train_df[\"median_house_value\"]\n",
    "\n",
    "X_test_raw = test_df.drop(columns=[\"median_house_value\", \"ocean_proximity\"], errors='ignore')\n",
    "Y_test_raw = test_df[\"median_house_value\"]\n",
    "\n",
    "# Scaling\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_x.fit_transform(X_train_raw.values)\n",
    "Y_train = scaler_y.fit_transform(Y_train_raw.values.reshape(-1, 1))\n",
    "\n",
    "X_test = scaler_x.transform(X_test_raw.values)\n",
    "Y_test = scaler_y.transform(Y_test_raw.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "427e497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup DataLoaders\n",
    "train_dataset = HousePriceDataset(X_train, Y_train)\n",
    "val_dataset = HousePriceDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b1d52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize Model\n",
    "device = torch.device(\"cuda\")\n",
    "model_inp = X_train.shape[1]\n",
    "model = HousePricePredictor(input_dim=model_inp)\n",
    "model.to(device)\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5c78a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training on cuda...\n",
      "Epoch [1/50] Train Loss: 0.7301 Val Loss: nan\n",
      "Epoch [2/50] Train Loss: 0.4406 Val Loss: nan\n",
      "Epoch [3/50] Train Loss: 0.3873 Val Loss: nan\n",
      "Epoch [4/50] Train Loss: 0.3533 Val Loss: nan\n",
      "Epoch [5/50] Train Loss: 0.3507 Val Loss: nan\n",
      "Epoch [6/50] Train Loss: 0.3383 Val Loss: nan\n",
      "Epoch [7/50] Train Loss: 0.3288 Val Loss: nan\n",
      "Epoch [8/50] Train Loss: 0.3220 Val Loss: nan\n",
      "Epoch [9/50] Train Loss: 0.3171 Val Loss: nan\n",
      "Epoch [10/50] Train Loss: 0.3173 Val Loss: nan\n",
      "Epoch [11/50] Train Loss: 0.3060 Val Loss: nan\n",
      "Epoch [12/50] Train Loss: 0.3044 Val Loss: nan\n",
      "Epoch [13/50] Train Loss: 0.3039 Val Loss: nan\n",
      "Epoch [14/50] Train Loss: 0.2939 Val Loss: nan\n",
      "Epoch [15/50] Train Loss: 0.2908 Val Loss: nan\n",
      "Epoch [16/50] Train Loss: 0.2862 Val Loss: nan\n",
      "Epoch [17/50] Train Loss: 0.2794 Val Loss: nan\n",
      "Epoch [18/50] Train Loss: 0.2824 Val Loss: nan\n",
      "Epoch [19/50] Train Loss: 0.2809 Val Loss: nan\n",
      "Epoch [20/50] Train Loss: 0.2745 Val Loss: nan\n",
      "Epoch [21/50] Train Loss: 0.2791 Val Loss: nan\n",
      "Epoch [22/50] Train Loss: 0.2719 Val Loss: nan\n",
      "Epoch [23/50] Train Loss: 0.2694 Val Loss: nan\n",
      "Epoch [24/50] Train Loss: 0.2680 Val Loss: nan\n",
      "Epoch [25/50] Train Loss: 0.2636 Val Loss: nan\n",
      "Epoch [26/50] Train Loss: 0.2628 Val Loss: nan\n",
      "Epoch [27/50] Train Loss: 0.2615 Val Loss: nan\n",
      "Epoch [28/50] Train Loss: 0.2628 Val Loss: nan\n",
      "Epoch [29/50] Train Loss: 0.2639 Val Loss: nan\n",
      "Epoch [30/50] Train Loss: 0.2560 Val Loss: nan\n",
      "Epoch [31/50] Train Loss: 0.2647 Val Loss: nan\n",
      "Epoch [32/50] Train Loss: 0.2527 Val Loss: nan\n",
      "Epoch [33/50] Train Loss: 0.2517 Val Loss: nan\n",
      "Epoch [34/50] Train Loss: 0.2549 Val Loss: nan\n",
      "Epoch [35/50] Train Loss: 0.2498 Val Loss: nan\n",
      "Epoch [36/50] Train Loss: 0.2545 Val Loss: nan\n",
      "Epoch [37/50] Train Loss: 0.2488 Val Loss: nan\n",
      "Epoch [38/50] Train Loss: 0.2498 Val Loss: nan\n",
      "Epoch [39/50] Train Loss: 0.2533 Val Loss: nan\n",
      "Epoch [40/50] Train Loss: 0.2519 Val Loss: nan\n",
      "Epoch [41/50] Train Loss: 0.2506 Val Loss: nan\n",
      "Epoch [42/50] Train Loss: 0.2420 Val Loss: nan\n",
      "Epoch [43/50] Train Loss: 0.2446 Val Loss: nan\n",
      "Epoch [44/50] Train Loss: 0.2451 Val Loss: nan\n",
      "Epoch [45/50] Train Loss: 0.2467 Val Loss: nan\n",
      "Epoch [46/50] Train Loss: 0.2408 Val Loss: nan\n",
      "Epoch [47/50] Train Loss: 0.2425 Val Loss: nan\n",
      "Epoch [48/50] Train Loss: 0.2390 Val Loss: nan\n",
      "Epoch [49/50] Train Loss: 0.2362 Val Loss: nan\n",
      "Epoch [50/50] Train Loss: 0.2384 Val Loss: nan\n"
     ]
    }
   ],
   "source": [
    "# 4. Training Loop\n",
    "num_epochs = 50\n",
    "print(f\"Starting model training on {device}...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = model_training_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    val_loss = model_validation_epoch(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} \"\n",
    "        f\"Val Loss: {val_loss:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "326537b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler X saved to ../inference/scaler_x.joblib\n",
      "Scaler Y saved to ../inference/scaler_y.joblib\n",
      "Model saved to ../inference/model_parameters.pth\n"
     ]
    }
   ],
   "source": [
    "# 5. Export the trained model for future\n",
    "import joblib\n",
    "\n",
    "# Path where fitted StandardScaler from scikit learn is saved\n",
    "scaler_x_path = \"../inference/scaler_x.joblib\"\n",
    "scaler_y_path = \"../inference/scaler_y.joblib\"\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler_x, scaler_x_path)\n",
    "joblib.dump(scaler_y, scaler_y_path)\n",
    "print(f\"Scaler X saved to {scaler_x_path}\")\n",
    "print(f\"Scaler Y saved to {scaler_y_path}\")\n",
    "\n",
    "# Define path\n",
    "model_path = \"../inference/model_parameters.pth\"\n",
    "\n",
    "# Save the state_dict (model weights and biases [parameters])\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
